{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from collections import OrderedDict, defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.model_selection import GroupKFold\n",
    "import matplotlib.pyplot as plt\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmseg.registry import DATASETS, TRANSFORMS, MODELS, METRICS\n",
    "from mmseg.datasets import BaseSegDataset\n",
    "from mmseg.models.segmentors import EncoderDecoder\n",
    "from mmseg.models.decode_heads import ASPPHead, FCNHead, SegformerHead \n",
    "from mmseg.models.utils.wrappers import resize\n",
    "\n",
    "\n",
    "from mmengine.config import Config\n",
    "from mmengine.dataset import Compose\n",
    "from mmengine.runner import Runner, load_checkpoint\n",
    "from mmengine.evaluator import BaseMetric\n",
    "from mmengine.logging import MMLogger, print_log\n",
    "from mmengine.structures import PixelData\n",
    "\n",
    "from mmcv.transforms import BaseTransform"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES = [\n",
    "    'finger-1', 'finger-2', 'finger-3', 'finger-4', 'finger-5',\n",
    "    'finger-6', 'finger-7', 'finger-8', 'finger-9', 'finger-10',\n",
    "    'finger-11', 'finger-12', 'finger-13', 'finger-14', 'finger-15',\n",
    "    'finger-16', 'finger-17', 'finger-18', 'finger-19', 'Trapezium',\n",
    "    'Trapezoid', 'Capitate', 'Hamate', 'Scaphoid', 'Lunate',\n",
    "    'Triquetrum', 'Pisiform', 'Radius', 'Ulna',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASS2IND = {v: i for i, v in enumerate(CLASSES)}\n",
    "IND2CLASS = {v: k for k, v in CLASS2IND.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PostProcessResultMixin:\n",
    "    def postprocess_result(self,\n",
    "                           seg_logits,\n",
    "                           data_samples):\n",
    "        \"\"\" Convert results list to `SegDataSample`.\n",
    "        Args:\n",
    "            seg_logits (Tensor): The segmentation results, seg_logits from\n",
    "                model of each input image.\n",
    "            data_samples (list[:obj:`SegDataSample`]): The seg data samples.\n",
    "                It usually includes information such as `metainfo` and\n",
    "                `gt_sem_seg`. Default to None.\n",
    "        Returns:\n",
    "            list[:obj:`SegDataSample`]: Segmentation results of the\n",
    "            input images. Each SegDataSample usually contain:\n",
    "\n",
    "            - ``pred_sem_seg``(PixelData): Prediction of semantic segmentation.\n",
    "            - ``seg_logits``(PixelData): Predicted logits of semantic\n",
    "                segmentation before normalization.\n",
    "        \"\"\"\n",
    "        batch_size, C, H, W = seg_logits.shape\n",
    "\n",
    "        if data_samples is None:\n",
    "            data_samples = [SegDataSample() for _ in range(batch_size)]\n",
    "            only_prediction = True\n",
    "        else:\n",
    "            only_prediction = False\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            if not only_prediction:\n",
    "                img_meta = data_samples[i].metainfo\n",
    "                # remove padding area\n",
    "                if 'img_padding_size' not in img_meta:\n",
    "                    padding_size = img_meta.get('padding_size', [0] * 4)\n",
    "                else:\n",
    "                    padding_size = img_meta['img_padding_size']\n",
    "                padding_left, padding_right, padding_top, padding_bottom =\\\n",
    "                    padding_size\n",
    "                # i_seg_logits shape is 1, C, H, W after remove padding\n",
    "                i_seg_logits = seg_logits[i:i + 1, :,\n",
    "                                          padding_top:H - padding_bottom,\n",
    "                                          padding_left:W - padding_right]\n",
    "\n",
    "                flip = img_meta.get('flip', None)\n",
    "                if flip:\n",
    "                    flip_direction = img_meta.get('flip_direction', None)\n",
    "                    assert flip_direction in ['horizontal', 'vertical']\n",
    "                    if flip_direction == 'horizontal':\n",
    "                        i_seg_logits = i_seg_logits.flip(dims=(3, ))\n",
    "                    else:\n",
    "                        i_seg_logits = i_seg_logits.flip(dims=(2, ))\n",
    "\n",
    "                # resize as original shape\n",
    "                i_seg_logits = resize(\n",
    "                    i_seg_logits,\n",
    "                    size=img_meta['ori_shape'],\n",
    "                    mode='bilinear',\n",
    "                    align_corners=self.align_corners,\n",
    "                    warning=False).squeeze(0)\n",
    "            else:\n",
    "                i_seg_logits = seg_logits[i]\n",
    "\n",
    "            i_seg_logits = i_seg_logits.sigmoid()\n",
    "            i_seg_pred = (i_seg_logits > 0.5).to(i_seg_logits)\n",
    "                \n",
    "            data_samples[i].set_data({\n",
    "                'seg_logits':\n",
    "                PixelData(**{'data': i_seg_logits}),\n",
    "                'pred_sem_seg':\n",
    "                PixelData(**{'data': i_seg_pred})\n",
    "            })\n",
    "\n",
    "        return data_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@MODELS.register_module()\n",
    "class EncoderDecoderWithoutArgmax(PostProcessResultMixin, EncoderDecoder):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossByFeatMixIn:\n",
    "    def loss_by_feat(self, seg_logits, batch_data_samples) -> dict:\n",
    "        \"\"\"Compute segmentation loss.\n",
    "\n",
    "        Args:\n",
    "            seg_logits (Tensor): The output from decode head forward function.\n",
    "            batch_data_samples (List[:obj:`SegDataSample`]): The seg\n",
    "                data samples. It usually includes information such\n",
    "                as `metainfo` and `gt_sem_seg`.\n",
    "\n",
    "        Returns:\n",
    "            dict[str, Tensor]: a dictionary of loss components\n",
    "        \"\"\"\n",
    "\n",
    "        seg_label = self._stack_batch_gt(batch_data_samples)\n",
    "        loss = dict()\n",
    "        seg_logits = resize(\n",
    "            input=seg_logits,\n",
    "            size=seg_label.shape[2:],\n",
    "            mode='bilinear',\n",
    "            align_corners=self.align_corners)\n",
    "        if self.sampler is not None:\n",
    "            seg_weight = self.sampler.sample(seg_logits, seg_label)\n",
    "        else:\n",
    "            seg_weight = None\n",
    "\n",
    "        if not isinstance(self.loss_decode, nn.ModuleList):\n",
    "            losses_decode = [self.loss_decode]\n",
    "        else:\n",
    "            losses_decode = self.loss_decode\n",
    "        for loss_decode in losses_decode:\n",
    "            if loss_decode.loss_name not in loss:\n",
    "                loss[loss_decode.loss_name] = loss_decode(\n",
    "                    seg_logits,\n",
    "                    seg_label,\n",
    "                    weight=seg_weight,\n",
    "                    ignore_index=self.ignore_index)\n",
    "            else:\n",
    "                loss[loss_decode.loss_name] += loss_decode(\n",
    "                    seg_logits,\n",
    "                    seg_label,\n",
    "                    weight=seg_weight,\n",
    "                    ignore_index=self.ignore_index)\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@MODELS.register_module()\n",
    "class ASPPHeadWithoutAccuracy(LossByFeatMixIn, ASPPHead):\n",
    "    pass\n",
    "\n",
    "@MODELS.register_module()\n",
    "class FCNHeadWithoutAccuracy(LossByFeatMixIn, FCNHead):\n",
    "    pass\n",
    "\n",
    "@MODELS.register_module()\n",
    "class SegformerHeadWithoutAccuracy(LossByFeatMixIn, SegformerHead):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "@TRANSFORMS.register_module()\n",
    "class LoadXRayAnnotations(BaseTransform):\n",
    "    def transform(self, result):\n",
    "        label_path = result[\"seg_map_path\"]\n",
    "        \n",
    "        image_size = (512, 512)\n",
    "        \n",
    "        # process a label of shape (H, W, NC)\n",
    "        label_shape = image_size + (len(CLASSES), )\n",
    "        label = np.zeros(label_shape, dtype=np.uint8)\n",
    "        \n",
    "        # read label file\n",
    "        with open(label_path, \"r\") as f:\n",
    "            annotations = json.load(f)\n",
    "        annotations = annotations[\"annotations\"]\n",
    "        \n",
    "        # iterate each class\n",
    "        for ann in annotations:\n",
    "            c = ann[\"label\"]\n",
    "            class_ind = CLASS2IND[c]\n",
    "            points = np.array(ann[\"points\"])\n",
    "            \n",
    "            # polygon to mask\n",
    "            class_label = np.zeros(image_size, dtype=np.uint8)\n",
    "            cv2.fillPoly(class_label, [points], 1)\n",
    "            label[..., class_ind] = class_label\n",
    "        \n",
    "        result[\"gt_seg_map\"] = label\n",
    "        \n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "@TRANSFORMS.register_module()\n",
    "class TransposeAnnotations(BaseTransform):\n",
    "    def transform(self, result):\n",
    "        result[\"gt_seg_map\"] = np.transpose(result[\"gt_seg_map\"], (2, 0, 1))\n",
    "        \n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "@METRICS.register_module()\n",
    "class DiceMetric(BaseMetric):\n",
    "    def __init__(self,\n",
    "                 collect_device='cpu',\n",
    "                 prefix=None,\n",
    "                 **kwargs):\n",
    "        super().__init__(collect_device=collect_device, prefix=prefix)\n",
    "        \n",
    "    @staticmethod\n",
    "    def dice_coef(y_true, y_pred):        \n",
    "        y_true_f = y_true.flatten(-2)\n",
    "        y_pred_f = y_pred.flatten(-2)\n",
    "        intersection = torch.sum(y_true_f * y_pred_f, -1)\n",
    "\n",
    "        eps = 0.0001\n",
    "        return (2. * intersection + eps) / (torch.sum(y_true_f, -1) + torch.sum(y_pred_f, -1) + eps)\n",
    "\n",
    "    def process(self, data_batch, data_samples):\n",
    "        \"\"\"Process one batch of data and data_samples.\n",
    "\n",
    "        The processed results should be stored in ``self.results``, which will\n",
    "        be used to compute the metrics when all batches have been processed.\n",
    "\n",
    "        Args:\n",
    "            data_batch (dict): A batch of data from the dataloader.\n",
    "            data_samples (Sequence[dict]): A batch of outputs from the model.\n",
    "        \"\"\"\n",
    "        for data_sample in data_samples:\n",
    "            pred_label = data_sample['pred_sem_seg']['data']\n",
    "            \n",
    "            label = data_sample['gt_sem_seg']['data'].to(pred_label)\n",
    "            self.results.append(\n",
    "                self.dice_coef(label, pred_label)\n",
    "            )\n",
    "\n",
    "    def compute_metrics(self, results):\n",
    "        \"\"\"Compute the metrics from processed results.\n",
    "\n",
    "        Args:\n",
    "            results (list): The processed results of each batch.\n",
    "\n",
    "        Returns:\n",
    "            Dict[str, float]: The computed metrics. The keys are the names of\n",
    "                the metrics, and the values are corresponding results.\n",
    "        \"\"\"\n",
    "        logger: MMLogger = MMLogger.get_current_instance()\n",
    "            \n",
    "        results = torch.stack(self.results, 0)        \n",
    "        dices_per_class = torch.mean(results, 0)\n",
    "        avg_dice = torch.mean(dices_per_class)\n",
    "            \n",
    "        ret_metrics = {\n",
    "            \"Dice\": dices_per_class.detach().cpu().numpy(),\n",
    "        }\n",
    "        # summary table\n",
    "        ret_metrics_summary = OrderedDict({\n",
    "            ret_metric: np.round(np.nanmean(ret_metric_value) * 100, 2)\n",
    "            for ret_metric, ret_metric_value in ret_metrics.items()\n",
    "        })\n",
    "        \n",
    "        metrics = {\n",
    "            \"mDice\": torch.mean(dices_per_class).item()\n",
    "        }\n",
    "\n",
    "        # each class table\n",
    "        ret_metrics.pop('aAcc', None)\n",
    "        ret_metrics_class = OrderedDict({\n",
    "            ret_metric: np.round(ret_metric_value * 100, 2)\n",
    "            for ret_metric, ret_metric_value in ret_metrics.items()\n",
    "        })\n",
    "        ret_metrics_class.update({'Class': CLASSES})\n",
    "        ret_metrics_class.move_to_end('Class', last=False)\n",
    "        class_table_data = PrettyTable()\n",
    "        for key, val in ret_metrics_class.items():\n",
    "            class_table_data.add_column(key, val)\n",
    "\n",
    "        print_log('per class results:', logger)\n",
    "        print_log('\\n' + class_table_data.get_string(), logger=logger)\n",
    "\n",
    "        return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting dataset_setting.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile dataset_setting.py\n",
    "\n",
    "# dataset settings\n",
    "dataset_type = 'XRayDataset'\n",
    "train_pipeline = [\n",
    "    dict(type='LoadImageFromFile'),\n",
    "    dict(type='LoadXRayAnnotations'),\n",
    "    dict(type='Resize', scale=(512, 512)),\n",
    "    dict(type='TransposeAnnotations'),\n",
    "    dict(type='PackSegInputs')\n",
    "]\n",
    "test_pipeline = [\n",
    "    dict(type='LoadImageFromFile'),\n",
    "    dict(type='Resize', scale=(512, 512)),\n",
    "    # add loading annotation after ``Resize`` because ground truth\n",
    "    # does not need to do resize data transform\n",
    "    # dict(type='LoadXRayAnnotations'),\n",
    "    # dict(type='TransposeAnnotations'),\n",
    "    dict(type='PackSegInputs')\n",
    "]\n",
    "train_dataloader = dict(\n",
    "    batch_size=1,\n",
    "    num_workers=1,\n",
    "    persistent_workers=True,\n",
    "    sampler=dict(type='InfiniteSampler', shuffle=True),\n",
    "    dataset=dict(\n",
    "        type=dataset_type,\n",
    "        is_train=True,\n",
    "        pipeline=train_pipeline\n",
    "    )\n",
    ")\n",
    "val_dataloader = dict(\n",
    "    batch_size=1,\n",
    "    num_workers=0,\n",
    "    sampler=dict(type='DefaultSampler', shuffle=False),\n",
    "    dataset=dict(\n",
    "        type=dataset_type,\n",
    "        is_train=False,\n",
    "        pipeline=test_pipeline\n",
    "    )\n",
    ")\n",
    "test_dataloader = val_dataloader\n",
    "\n",
    "val_evaluator = dict(type='DiceMetric')\n",
    "test_evaluator = val_evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting config_for_this_example.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile config_for_this_example.py\n",
    "\n",
    "# Train Segformer Mit B0\n",
    "_base_ = [\n",
    "    \"mmsegmentation/configs/_base_/models/segformer_mit-b0.py\",\n",
    "    \"dataset_setting.py\",\n",
    "    \"mmsegmentation/configs/_base_/default_runtime.py\"\n",
    "]\n",
    "\n",
    "data_preprocessor = dict(\n",
    "    type='SegDataPreProcessor',\n",
    "    mean=[0., 0., 0.],\n",
    "    std=[255., 255., 255.],\n",
    "    bgr_to_rgb=True,\n",
    "    size=(512, 512),\n",
    "    pad_val=0,\n",
    "    seg_pad_val=255,\n",
    ")\n",
    "\n",
    "model = dict(\n",
    "    type='EncoderDecoderWithoutArgmax',\n",
    "    init_cfg=dict(\n",
    "        type='Pretrained',\n",
    "        # load ADE20k pretrained EncoderDecoder from mmsegmentation\n",
    "        checkpoint=\"https://download.openmmlab.com/mmsegmentation/v0.5/segformer/segformer_mit-b0_512x512_160k_ade20k/segformer_mit-b0_512x512_160k_ade20k_20210726_101530-8ffa8fda.pth\"\n",
    "    ),\n",
    "    data_preprocessor=data_preprocessor,\n",
    "    decode_head=dict(\n",
    "        type='SegformerHeadWithoutAccuracy',\n",
    "        num_classes=29,\n",
    "        loss_decode=dict(\n",
    "            type='CrossEntropyLoss',\n",
    "            use_sigmoid=True,\n",
    "            loss_weight=1.0,\n",
    "        ),\n",
    "    ),\n",
    ")\n",
    "\n",
    "# optimizer\n",
    "optimizer = dict(type='AdamW', lr=0.00006, betas=(0.9, 0.999), weight_decay=0.01)\n",
    "optim_wrapper = dict(type='OptimWrapper', optimizer=optimizer, clip_grad=None)\n",
    "# learning policy\n",
    "param_scheduler = [\n",
    "    dict(\n",
    "        type='LinearLR', start_factor=1e-6, by_epoch=False, begin=0, end=1500\n",
    "    ),\n",
    "    dict(\n",
    "        type='PolyLR',\n",
    "        eta_min=0.0,\n",
    "        power=1.0,\n",
    "        begin=1500,\n",
    "        end=20000,\n",
    "        by_epoch=False,\n",
    "    )\n",
    "]\n",
    "# training schedule for 20k\n",
    "train_cfg = dict(type='IterBasedTrainLoop', max_iters=20000, val_interval=1000)\n",
    "\n",
    "val_cfg = dict(type='ValLoop')\n",
    "test_cfg = dict(type='TestLoop')\n",
    "default_hooks = dict(\n",
    "    timer=dict(type='IterTimerHook'),\n",
    "    logger=dict(type='LoggerHook', interval=50, log_metric_by_epoch=False),\n",
    "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
    "    checkpoint=dict(type='CheckpointHook', by_epoch=False, interval=2000),\n",
    "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
    "    visualization=dict(type='SegVisualizationHook')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/19 02:55:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "------------------------------------------------------------\n",
      "System environment:\n",
      "    sys.platform: linux\n",
      "    Python: 3.8.5 (default, Sep  4 2020, 07:30:14) [GCC 7.3.0]\n",
      "    CUDA available: True\n",
      "    numpy_random_seed: 1497004439\n",
      "    GPU 0: Tesla V100-PCIE-32GB\n",
      "    CUDA_HOME: None\n",
      "    GCC: gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\n",
      "    PyTorch: 2.0.1+cu117\n",
      "    PyTorch compiling details: PyTorch built with:\n",
      "  - GCC 9.3\n",
      "  - C++ Version: 201703\n",
      "  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: AVX2\n",
      "  - CUDA Runtime 11.7\n",
      "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86\n",
      "  - CuDNN 8.5\n",
      "  - Magma 2.6.1\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.7, CUDNN_VERSION=8.5.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
      "\n",
      "    TorchVision: 0.8.2\n",
      "    OpenCV: 4.7.0\n",
      "    MMEngine: 0.7.4\n",
      "\n",
      "Runtime environment:\n",
      "    cudnn_benchmark: True\n",
      "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
      "    dist_cfg: {'backend': 'nccl'}\n",
      "    seed: 1497004439\n",
      "    Distributed launcher: none\n",
      "    Distributed training: False\n",
      "    GPU number: 1\n",
      "------------------------------------------------------------\n",
      "\n",
      "06/19 02:55:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
      "norm_cfg = dict(type='SyncBN', requires_grad=True)\n",
      "data_preprocessor = dict(\n",
      "    type='SegDataPreProcessor',\n",
      "    mean=[0.0, 0.0, 0.0],\n",
      "    std=[255.0, 255.0, 255.0],\n",
      "    bgr_to_rgb=True,\n",
      "    pad_val=0,\n",
      "    seg_pad_val=255,\n",
      "    size=(512, 512))\n",
      "model = dict(\n",
      "    type='EncoderDecoderWithoutArgmax',\n",
      "    data_preprocessor=dict(\n",
      "        type='SegDataPreProcessor',\n",
      "        mean=[0.0, 0.0, 0.0],\n",
      "        std=[255.0, 255.0, 255.0],\n",
      "        bgr_to_rgb=True,\n",
      "        pad_val=0,\n",
      "        seg_pad_val=255,\n",
      "        size=(512, 512)),\n",
      "    pretrained=None,\n",
      "    backbone=dict(\n",
      "        type='MixVisionTransformer',\n",
      "        in_channels=3,\n",
      "        embed_dims=32,\n",
      "        num_stages=4,\n",
      "        num_layers=[2, 2, 2, 2],\n",
      "        num_heads=[1, 2, 5, 8],\n",
      "        patch_sizes=[7, 3, 3, 3],\n",
      "        sr_ratios=[8, 4, 2, 1],\n",
      "        out_indices=(0, 1, 2, 3),\n",
      "        mlp_ratio=4,\n",
      "        qkv_bias=True,\n",
      "        drop_rate=0.0,\n",
      "        attn_drop_rate=0.0,\n",
      "        drop_path_rate=0.1),\n",
      "    decode_head=dict(\n",
      "        type='SegformerHeadWithoutAccuracy',\n",
      "        in_channels=[32, 64, 160, 256],\n",
      "        in_index=[0, 1, 2, 3],\n",
      "        channels=256,\n",
      "        dropout_ratio=0.1,\n",
      "        num_classes=29,\n",
      "        norm_cfg=dict(type='SyncBN', requires_grad=True),\n",
      "        align_corners=False,\n",
      "        loss_decode=dict(\n",
      "            type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0)),\n",
      "    train_cfg=dict(),\n",
      "    test_cfg=dict(mode='whole'),\n",
      "    init_cfg=dict(\n",
      "        type='Pretrained',\n",
      "        checkpoint=\n",
      "        'https://download.openmmlab.com/mmsegmentation/v0.5/segformer/segformer_mit-b0_512x512_160k_ade20k/segformer_mit-b0_512x512_160k_ade20k_20210726_101530-8ffa8fda.pth'\n",
      "    ))\n",
      "dataset_type = 'XRayDataset'\n",
      "train_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(type='LoadXRayAnnotations'),\n",
      "    dict(type='Resize', scale=(512, 512)),\n",
      "    dict(type='TransposeAnnotations'),\n",
      "    dict(type='PackSegInputs')\n",
      "]\n",
      "test_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(type='Resize', scale=(512, 512)),\n",
      "    dict(type='PackSegInputs')\n",
      "]\n",
      "train_dataloader = dict(\n",
      "    batch_size=1,\n",
      "    num_workers=1,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(type='InfiniteSampler', shuffle=True),\n",
      "    dataset=dict(\n",
      "        type='XRayDataset',\n",
      "        is_train=True,\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(type='LoadXRayAnnotations'),\n",
      "            dict(type='Resize', scale=(512, 512)),\n",
      "            dict(type='TransposeAnnotations'),\n",
      "            dict(type='PackSegInputs')\n",
      "        ]))\n",
      "val_dataloader = dict(\n",
      "    batch_size=1,\n",
      "    num_workers=0,\n",
      "    sampler=dict(type='DefaultSampler', shuffle=False),\n",
      "    dataset=dict(\n",
      "        type='XRayDataset',\n",
      "        is_train=False,\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(type='Resize', scale=(512, 512)),\n",
      "            dict(type='PackSegInputs')\n",
      "        ]))\n",
      "test_dataloader = dict(\n",
      "    batch_size=1,\n",
      "    num_workers=0,\n",
      "    sampler=dict(type='DefaultSampler', shuffle=False),\n",
      "    dataset=dict(\n",
      "        type='XRayDataset',\n",
      "        is_train=False,\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(type='Resize', scale=(512, 512)),\n",
      "            dict(type='PackSegInputs')\n",
      "        ]))\n",
      "val_evaluator = dict(type='DiceMetric')\n",
      "test_evaluator = dict(type='DiceMetric')\n",
      "default_scope = 'mmseg'\n",
      "env_cfg = dict(\n",
      "    cudnn_benchmark=True,\n",
      "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0),\n",
      "    dist_cfg=dict(backend='nccl'))\n",
      "vis_backends = [dict(type='LocalVisBackend')]\n",
      "visualizer = dict(\n",
      "    type='SegLocalVisualizer',\n",
      "    vis_backends=[dict(type='LocalVisBackend')],\n",
      "    name='visualizer')\n",
      "log_processor = dict(by_epoch=False)\n",
      "log_level = 'INFO'\n",
      "load_from = None\n",
      "resume = False\n",
      "tta_model = dict(type='SegTTAModel')\n",
      "optimizer = dict(type='AdamW', lr=6e-05, betas=(0.9, 0.999), weight_decay=0.01)\n",
      "optim_wrapper = dict(\n",
      "    type='OptimWrapper',\n",
      "    optimizer=dict(\n",
      "        type='AdamW', lr=6e-05, betas=(0.9, 0.999), weight_decay=0.01),\n",
      "    clip_grad=None)\n",
      "param_scheduler = [\n",
      "    dict(\n",
      "        type='LinearLR', start_factor=1e-06, by_epoch=False, begin=0,\n",
      "        end=1500),\n",
      "    dict(\n",
      "        type='PolyLR',\n",
      "        eta_min=0.0,\n",
      "        power=1.0,\n",
      "        begin=1500,\n",
      "        end=20000,\n",
      "        by_epoch=False)\n",
      "]\n",
      "train_cfg = dict(type='IterBasedTrainLoop', max_iters=20000, val_interval=1000)\n",
      "val_cfg = dict(type='ValLoop')\n",
      "test_cfg = dict(type='TestLoop')\n",
      "default_hooks = dict(\n",
      "    timer=dict(type='IterTimerHook'),\n",
      "    logger=dict(type='LoggerHook', interval=50, log_metric_by_epoch=False),\n",
      "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
      "    checkpoint=dict(type='CheckpointHook', by_epoch=False, interval=2000),\n",
      "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
      "    visualization=dict(type='SegVisualizationHook'))\n",
      "launcher = 'none'\n",
      "work_dir = './work_dirs/baseline'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/mmseg/models/builder.py:36: UserWarning: ``build_loss`` would be deprecated soon, please use ``mmseg.registry.MODELS.build()`` \n",
      "  warnings.warn('``build_loss`` would be deprecated soon, please use '\n",
      "/opt/conda/lib/python3.8/site-packages/mmseg/models/losses/cross_entropy_loss.py:235: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/19 02:55:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
      "06/19 02:55:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "before_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DistSamplerSeedHook                \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) SegVisualizationHook               \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) SegVisualizationHook               \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_train:\n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_test_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) SegVisualizationHook               \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_run:\n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/mmseg/engine/hooks/visualization_hook.py:61: UserWarning: The draw is False, it means that the hook for visualization will not take effect. The results will NOT be visualized or stored.\n",
      "  warnings.warn('The draw is False, it means that the '\n"
     ]
    }
   ],
   "source": [
    "# load config\n",
    "cfg = Config.fromfile(\"config_for_this_example.py\")\n",
    "cfg.launcher = \"none\"\n",
    "cfg.work_dir = os.path.join('./work_dirs', \"baseline\")\n",
    "\n",
    "# resume training\n",
    "cfg.resume = False\n",
    "\n",
    "runner = Runner.from_cfg(cfg)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python native\n",
    "import os\n",
    "\n",
    "# external library\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# torch\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# visualization\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/mmseg/models/builder.py:36: UserWarning: ``build_loss`` would be deprecated soon, please use ``mmseg.registry.MODELS.build()`` \n",
      "  warnings.warn('``build_loss`` would be deprecated soon, please use '\n",
      "/opt/conda/lib/python3.8/site-packages/mmseg/models/losses/cross_entropy_loss.py:235: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = MODELS.build(cfg.model)\n",
    "\n",
    "IMAGE_ROOT = \"/opt/ml/input/data/test/DCM\" # 경로설정\n",
    "SAVE_DIR = \"/opt/ml/input/code/work_dirs/baseline/segformer_rotate_pth/\" # 경로설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loads checkpoint by local backend from path: /opt/ml/input/code/work_dirs/baseline/segformer_rotate_pth/iter_20000.pth\n"
     ]
    }
   ],
   "source": [
    "checkpoint = load_checkpoint(\n",
    "    model,\n",
    "    os.path.join(SAVE_DIR,'iter_20000.pth'),\n",
    "    map_location='cpu'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _preprare_data(imgs, model):\n",
    "    for t in cfg.test_pipeline:\n",
    "        if t.get('type') in ['LoadXRayAnnotations','TransposeAnnotations']:\n",
    "            cfg.test_pipeline.remove(t)\n",
    "            \n",
    "    is_batch = True\n",
    "    if not isinstance(imgs, (list, tuple)):\n",
    "        imgs = [imgs]\n",
    "        is_batch = False\n",
    "\n",
    "    if isinstance(imgs[0], np.ndarray):\n",
    "        cfg.test_pipeline[0]['type'] = 'LoadImageFromNDArray'\n",
    "\n",
    "    # TODO: Consider using the singleton pattern to avoid building\n",
    "    # a pipeline for each inference\n",
    "    pipeline = Compose(cfg.test_pipeline)\n",
    "\n",
    "    data = defaultdict(list)\n",
    "    for img in imgs:\n",
    "        if isinstance(img, np.ndarray):\n",
    "            data_ = dict(img=img)\n",
    "        else:\n",
    "            data_ = dict(img_path=img)\n",
    "        data_ = pipeline(data_)\n",
    "        data['inputs'].append(data_['inputs'])\n",
    "        data['data_samples'].append(data_['data_samples'])\n",
    "\n",
    "    return data, is_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define colors\n",
    "PALETTE = [\n",
    "    (220, 20, 60), (119, 11, 32), (0, 0, 142), (0, 0, 230), (106, 0, 228),\n",
    "    (0, 60, 100), (0, 80, 100), (0, 0, 70), (0, 0, 192), (250, 170, 30),\n",
    "    (100, 170, 30), (220, 220, 0), (175, 116, 175), (250, 0, 30), (165, 42, 42),\n",
    "    (255, 77, 255), (0, 226, 252), (182, 182, 255), (0, 82, 0), (120, 166, 157),\n",
    "    (110, 76, 0), (174, 57, 255), (199, 100, 0), (72, 0, 118), (255, 179, 240),\n",
    "    (0, 125, 92), (209, 0, 151), (188, 208, 182), (0, 220, 176),\n",
    "]\n",
    "\n",
    "# utility function\n",
    "# this does not care overlap\n",
    "def label2rgb(label):\n",
    "    image_size = label.shape[1:] + (3, )\n",
    "    image = np.zeros(image_size, dtype=np.uint8)\n",
    "    \n",
    "    for i, class_label in enumerate(label):\n",
    "        image[class_label == 1] = PALETTE[i]\n",
    "        \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pngs = {\n",
    "    os.path.relpath(os.path.join(root, fname), start=IMAGE_ROOT)\n",
    "    for root, _dirs, files in os.walk(IMAGE_ROOT)\n",
    "    for fname in files\n",
    "    if os.path.splitext(fname)[1].lower() == \".png\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XRayInferenceDataset(Dataset):\n",
    "    def __init__(self, transforms=None):\n",
    "        _filenames = pngs\n",
    "        _filenames = np.array(sorted(_filenames))\n",
    "        \n",
    "        self.filenames = _filenames\n",
    "        # self.transforms = transforms\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.filenames)\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        image_name = self.filenames[item]\n",
    "        image_path = os.path.join(IMAGE_ROOT, image_name)\n",
    "        image = cv2.imread(image_path)\n",
    "            \n",
    "        return image, image_name , image_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_mask_to_rle(mask):\n",
    "    '''\n",
    "    mask: numpy array binary mask \n",
    "    1 - mask \n",
    "    0 - background\n",
    "    Returns encoded run length \n",
    "    '''\n",
    "    pixels = mask.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)\n",
    "\n",
    "def decode_rle_to_mask(rle, height, width):\n",
    "    s = rle.split()\n",
    "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
    "    starts -= 1\n",
    "    ends = starts + lengths\n",
    "    img = np.zeros(height * width, dtype=np.uint8)\n",
    "    \n",
    "    for lo, hi in zip(starts, ends):\n",
    "        img[lo:hi] = 1\n",
    "    \n",
    "    return img.reshape(height, width)\n",
    "\n",
    "def test(model, data_loader, thr=0.5):\n",
    "    rles = []\n",
    "    filename_and_class = []\n",
    "    with torch.no_grad():\n",
    "        n_class = len(CLASSES)\n",
    "\n",
    "        for step, (images, image_names, image_path) in tqdm(enumerate(data_loader), total=len(data_loader)):\n",
    "            # images = images.cuda()    \n",
    "            images = image_path\n",
    "            data, is_batch = _preprare_data(images, model)\n",
    "            results = model.test_step(data)\n",
    "            results = results[0].pred_sem_seg.data\n",
    "            results = (results > thr).detach().cpu().numpy()\n",
    "            results = results.reshape(1,29,2048,2048)\n",
    "            # print(results.shape)\n",
    "            \n",
    "            for output, image_name in zip(results, image_names):\n",
    "                for c, segm in enumerate(output):\n",
    "                    rle = encode_mask_to_rle(segm)\n",
    "                    rles.append(rle)\n",
    "                    filename_and_class.append(f\"{IND2CLASS[c]}_{image_name}\")\n",
    "                    \n",
    "    return rles, filename_and_class\n",
    "        \n",
    "                                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = XRayInferenceDataset(transforms=None)\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_dataset, \n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    "    drop_last=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b39c855285e4505878819ff722840c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=300.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29, 2048, 2048) ID040/image1661319116107.png\n",
      "(29, 2048, 2048) ID040/image1661319145363.png\n",
      "(29, 2048, 2048) ID041/image1661319356239.png\n",
      "(29, 2048, 2048) ID041/image1661319390106.png\n",
      "(29, 2048, 2048) ID042/image1661320372752.png\n",
      "(29, 2048, 2048) ID042/image1661320397148.png\n",
      "(29, 2048, 2048) ID043/image1661320538919.png\n",
      "(29, 2048, 2048) ID043/image1661320557045.png\n",
      "(29, 2048, 2048) ID044/image1661320671343.png\n",
      "(29, 2048, 2048) ID044/image1661320722689.png\n",
      "(29, 2048, 2048) ID045/image1661320864475.png\n",
      "(29, 2048, 2048) ID045/image1661320892395.png\n",
      "(29, 2048, 2048) ID046/image1661320944318.png\n",
      "(29, 2048, 2048) ID046/image1661320972355.png\n",
      "(29, 2048, 2048) ID047/image1661389291522.png\n",
      "(29, 2048, 2048) ID047/image1661389310383.png\n",
      "(29, 2048, 2048) ID048/image1661389524954.png\n",
      "(29, 2048, 2048) ID048/image1661389553713.png\n",
      "(29, 2048, 2048) ID049/image1661389595277.png\n",
      "(29, 2048, 2048) ID049/image1661389621012.png\n",
      "(29, 2048, 2048) ID068/image1661735854451.png\n",
      "(29, 2048, 2048) ID068/image1661735882043.png\n",
      "(29, 2048, 2048) ID137/image1662340967509.png\n",
      "(29, 2048, 2048) ID137/image1662340984526.png\n",
      "(29, 2048, 2048) ID138/image1662341048902.png\n"
     ]
    }
   ],
   "source": [
    "rles, filename_and_class = test(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(os.path.join(IMAGE_ROOT, filename_and_class[0].split(\"_\")[1]))\n",
    "\n",
    "preds = []\n",
    "for rle in rles[:len(CLASSES)]:\n",
    "    pred = decode_rle_to_mask(rle, height=2048, width=2048)\n",
    "    preds.append(pred)\n",
    "\n",
    "preds = np.stack(preds, 0)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(24, 12))\n",
    "ax[0].imshow(image)    # remove channel dimension\n",
    "ax[1].imshow(label2rgb(preds))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes, filename = zip(*[x.split(\"_\") for x in filename_and_class])\n",
    "\n",
    "image_name = [os.path.basename(f) for f in filename]\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"image_name\": image_name,\n",
    "    \"class\": classes,\n",
    "    \"rle\": rles,\n",
    "})\n",
    "\n",
    "df.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(os.path.join(SAVE_DIR,\"output.csv\"), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
